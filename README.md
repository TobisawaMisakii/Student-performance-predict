# Student Performance Prediction

`github`仓库地址：https://github.com/TobisawaMisakii/Student-performance-predict

## 问题
对学生的成绩进行分类预测，将学生的成绩（G1、G2、G3，分数范围为 0~20）转化为分类标签，使用三种分类方法预测其等级类别。
数据集来自学生的葡萄牙语记录`student-por.csv`，含 649 个样本，33 个特征。

## 方法

### 多个预测任务

| 任务编号 | 输入特征          | 预测目标     |
| -------- | --------------- |----------|
| 1        | 前30个学生背景特征  | G1、G2、G3 |
| 2        | 前30个特征 +G1    | G2、G3    |
| 3        | 前30个特征 +G1+G2 | G3 |

### 数据预处理

具体实现见`data_preprocessing.py`

#### 类别特征处理

- 使用`pd.get_dummies`进行独热编码
- 设置`drop_first=True`
- e.g. 原始特征"school"（取值GP/MS）→转换为"school_MS"（0或1）

#### 数值特征标准化

- 采用`StandardScaler`进行Z-score标准化：
- 处理效果：
  - 使所有特征具有零均值和单位方差
  - 提升模型收敛速度（尤其对逻辑回归和KNN重要）\

#### 灵活的输出配置

- 通过`predict_kws`参数支持：
  - 单输出（如['G3']）
  - 多输出（如['G2','G3']）
- 输出格式：
  - y_train/y_test为二维numpy数组
  - 每列对应一个输出变量

#### train/test 划分

- 采用简单分块划分（非随机）：
  - 测试集：每5个样本取第1个（20%）
  - 训练集：剩余样本（80%）

## 实验结果

直接预测0-20分数：

| 模型\精度               | G3（1个输出） | G2+G3（2个输出） | G1+G2+G3（3个输出）      |
| ----------------------- | ------------- | ---------------- | ------------------------ |
| **KNN**                 | 0.1385        | 0.1154 / 0.0923  | 0.1231 / 0.0923 / 0.1000 |
| **Logistic Regression** | 0.2846        | 0.1538 / 0.2000  | 0.1077 / 0.1154 / 0.1462 |
| **Decision Tree**       | 0.3923        | 0.2385 / 0.2846  | 0.1154 / 0.1231 / 0.1154 |

将0-20分数分为5类，$[0, 4], (4, 8] ... (16, 20]$，构建为5分类任务：（实际仓库中的最后实现）

| 模型\精度               | G3（1个输出） | G2/G3（2个输出） | G1/G2/G3（3个输出）      |
| ----------------------- | ------------- | ---------------- | ------------------------ |
| **KNN**                 | 0.5385        | 0.5308 / 0.5231  | 0.4923 / 0.5000 / 0.5231 |
| **Logistic Regression** | 0.7692        | 0.6923 / 0.7077  | 0.4538 / 0.5000 / 0.5231 |
| **Decision Tree**       | 0.7692        | 0.6462 / 0.6923  | 0.4385 / 0.4692 / 0.4462 |

其他实验结果见仓库`output`文件夹，包括**三种模型*三种预测模式**，其中每一个文件夹（以`output/Decision Tree/2`为例）：

- 表示使用Decision Tree，预测**2个**输出（G2， G3）
- 包含：
  - `accuracy_1.txt`: 第一个输出(G2)的预测准确度
  - `accuracy_2.txt`: 第二个输出(G3)的预测准确度
  - `cls_report_1.csv`: 第一个输出(G2)的分类任务报告，包括准确率、召回率、F1 score、support等结果
  - `cls_report_2.csv`: 第二个输出(G3)的分类任务报告
  - `confusion_matrix_1.png`: 第一个输出(G2)的混淆矩阵，对角线越明显越成功
  - `confusion_matrix_2.png`: 第二个输出(G3)的混淆矩阵

## 结果讨论

### 原始分数预测

1. **准确率极其低**，直接预测 0~20 原始分数的多分类问题非常困难，可能原因是是类别过多时，模型难泛化，且对于分类目标的体量而言数据集过小。
2. **决策树整体表现最好**，尤其在 G1 和 G2 任务中较为稳定，其对非线性、离散特征建模能力更强。
3. **Logistic Regression 收敛困难**，选择参数为$max\_iter = 5000$，最大迭代次数设置过小会导致直接无法收敛，在 G2、G3 的预测中表现已经很差。
4. **KNN 表现最差**，不管输出维度多少都显示出非常羸弱的预测能力，可能因为样本过于稀疏，但维度较高。

### 五分类预测

1. **类别简化效应**：从21类降至5类，显著降低了分类难度，错误容忍度显著提高：即使预测偏差±4分仍可能落在正确类别
2. **数据分布简化**：检查原始数据发现，极端低分（0-4）和高分（16-20）样本较少，中间分数集中，5分类不一定实现了更好的样本平衡，可能可以采取更好的分段策略提高分类准确度

## 结论

- 成绩原始分数作为多分类任务存在较大挑战（最高准确率0.3923），将成绩转为较少类别（例如 5 类）以简化任务（最高准确率达0.7692）；
- 模型表现差异：
  - 决策树在原始分数预测中表现最优
  - 逻辑回归在5分类场景中优势明显
  - KNN模型始终表现最弱
- 任务复杂度影响：
  - 输出变量越多预测难度越大
  - G3预测从包含G1+G2作为输入特征中获益最大
- 可以考虑成绩的连续性特性，改为回归任务（如随机森林、XGBoost）进行建模，最后进行取整即可。

- 可选的超参数优化设置：

  - KNN：优化k值（3-15范围）和距离度量
  - 逻辑回归：尝试l1/l2正则化，不同求解器
  - 决策树：调整最大深度（3-10）和最小样本分裂数

## 其他文件

`histogram.py`, `output/histogram.png`为尝试用G3均分学生至5类，并构建直方图